{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going through OpenML Basic Usage\n",
    "https://openml.github.io/openml-python/stable/usage.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import openml\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Either put your API key below or in the ~/.openml/config file as\n",
    "# specified on the OpenML Basic Usage page\n",
    "# apikey = '<your API key>'\n",
    "# openml.config.apikey = apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "datasets = openml.datasets.list_datasets()\n",
    "\n",
    "# NOTE: the line below is different from the Basic Usage \n",
    "datasets_df = pd.DataFrame.from_dict(datasets, orient='index')\n",
    "\n",
    "datasets_df.set_index('did', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining and filtering by metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets: 19526\n",
      "Index(['NumberOfMissingValues', 'name', 'NumberOfClasses',\n",
      "       'NumberOfInstancesWithMissingValues', 'NumberOfInstances',\n",
      "       'MajorityClassSize', 'NumberOfSymbolicFeatures', 'format',\n",
      "       'NumberOfFeatures', 'status', 'MinorityClassSize',\n",
      "       'NumberOfNumericFeatures', 'MaxNominalAttDistinctValues'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('Number of datasets:', datasets_df.shape[0])\n",
    "print(datasets_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumberOfMissingValues                      0\n",
      "name                                  anneal\n",
      "NumberOfClasses                            6\n",
      "NumberOfInstancesWithMissingValues         0\n",
      "NumberOfInstances                        898\n",
      "MajorityClassSize                        684\n",
      "NumberOfSymbolicFeatures                  33\n",
      "format                                  ARFF\n",
      "NumberOfFeatures                          39\n",
      "status                                active\n",
      "MinorityClassSize                          0\n",
      "NumberOfNumericFeatures                    6\n",
      "MaxNominalAttDistinctValues               10\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(datasets_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets without any missing values: 19327\n"
     ]
    }
   ],
   "source": [
    "print('Number of datasets without any missing values:', \\\n",
    "      datasets_df[datasets_df.NumberOfInstancesWithMissingValues == 0]\n",
    "      .shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets with numeric features: 19210\n"
     ]
    }
   ],
   "source": [
    "print('Number of datasets with numeric features:', \\\n",
    "      datasets_df[(datasets_df.NumberOfNumericFeatures > 0) & \n",
    "                  (datasets_df.NumberOfInstancesWithMissingValues == 0)]\n",
    "      .shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets with numeric features and no symbolic features: 283\n"
     ]
    }
   ],
   "source": [
    "print('Number of datasets with numeric features and no symbolic features:', \\\n",
    "      datasets_df[(datasets_df.NumberOfSymbolicFeatures == 0) &\n",
    "                  (datasets_df.NumberOfNumericFeatures > 0) & \n",
    "                  (datasets_df.NumberOfInstancesWithMissingValues == 0)]\n",
    "      .shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "BadNominalValue",
     "evalue": "Data value not found in nominal declaration, at line 50.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadNominalValue\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-b7bc9663233e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# NOTE: Not all dataset_ids seem to work. For example, ids 0 and 1 process with error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdataset_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m23\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6357\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/u/nealbray/.local/lib/python3.4/site-packages/openml-0.3.0-py3.4.egg/openml/datasets/functions.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(dataset_id)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_dataset_from_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marff_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nealbray/.local/lib/python3.4/site-packages/openml-0.3.0-py3.4.egg/openml/datasets/functions.py\u001b[0m in \u001b[0;36m_create_dataset_from_description\u001b[0;34m(description, features, arff_file)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mdescription\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"oml:md5_checksum\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0mdata_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marff_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         features=features)\n\u001b[0m\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nealbray/.local/lib/python3.4/site-packages/openml-0.3.0-py3.4.egg/openml/datasets/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset_id, name, version, description, format, creator, contributor, collection_date, upload_date, language, licence, url, default_target_attribute, row_id_attribute, ignore_attribute, version_label, citation, tag, visibility, original_data_url, paper_url, update_comment, md5_checksum, data_file, features)\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_arff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                         logger.critical(\"Please check that the data file %s is there \"\n",
      "\u001b[0;32m/u/nealbray/.local/lib/python3.4/site-packages/openml-0.3.0-py3.4.egg/openml/datasets/dataset.py\u001b[0m in \u001b[0;36m_get_arff\u001b[0;34m(self, format)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdecode_arff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     def get_data(self, target=None, target_dtype=int, include_row_id=False,\n",
      "\u001b[0;32m/u/nealbray/.local/lib/python3.4/site-packages/openml-0.3.0-py3.4.egg/openml/datasets/dataset.py\u001b[0m in \u001b[0;36mdecode_arff\u001b[0;34m(fh)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArffDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             return decoder.decode(fh, encode_nominal=True,\n\u001b[0;32m--> 171\u001b[0;31m                                   return_type=return_type)\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\".gz\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nealbray/.local/lib/python3.4/site-packages/liac_arff-2.1.2.dev0-py3.4.egg/arff.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, encode_nominal, return_type)\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0;31m# print e\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nealbray/.local/lib/python3.4/site-packages/liac_arff-2.1.2.dev0-py3.4.egg/arff.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, encode_nominal, return_type)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             return self._decode(s, encode_nominal=encode_nominal,\n\u001b[0;32m--> 728\u001b[0;31m                                 matrix_type=return_type)\n\u001b[0m\u001b[1;32m    729\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mArffException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0;31m# print e\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nealbray/.local/lib/python3.4/site-packages/liac_arff-2.1.2.dev0-py3.4.egg/arff.py\u001b[0m in \u001b[0;36m_decode\u001b[0;34m(self, s, encode_nominal, matrix_type)\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;31m# DATA INSTANCES --------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mSTATE\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_TK_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m                 \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conversors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m             \u001b[0;31m# -----------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nealbray/.local/lib/python3.4/site-packages/liac_arff-2.1.2.dev0-py3.4.egg/arff.py\u001b[0m in \u001b[0;36mdecode_data\u001b[0;34m(self, s, conversors)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconversors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mBadDataFormat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconversors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nealbray/.local/lib/python3.4/site-packages/liac_arff-2.1.2.dev0-py3.4.egg/arff.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconversors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mBadDataFormat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconversors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nealbray/.local/lib/python3.4/site-packages/liac_arff-2.1.2.dev0-py3.4.egg/arff.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\\"\\''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conversor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nealbray/.local/lib/python3.4/site-packages/liac_arff-2.1.2.dev0-py3.4.egg/arff.py\u001b[0m in \u001b[0;36m_encoded_nominal\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    312\u001b[0m         the .arff file.'''\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadNominalValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoded_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBadNominalValue\u001b[0m: Data value not found in nominal declaration, at line 50."
     ]
    }
   ],
   "source": [
    "# NOTE: Not all dataset_ids seem to work. For example, ids 0 and 1 process with error.\n",
    "dataset_id = 23\n",
    "dataset = openml.datasets.get_dataset(6357)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X is simply a numpy array: <class 'numpy.ndarray'>\n",
      "Data shape and type: (1473, 10) float32\n"
     ]
    }
   ],
   "source": [
    "# get just the unlabeled data\n",
    "X = dataset.get_data()\n",
    "print('X is simply a numpy array:', type(X))\n",
    "print('Data shape and type:', X.shape, X.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wifes_age', 'Wifes_education', 'Husbands_education', 'Number_of_children_ever_born', 'Wifes_religion', 'Wifes_now_working%3F', 'Husbands_occupation', 'Standard-of-living_index', 'Media_exposure', 'Contraceptive_method_used']\n"
     ]
    }
   ],
   "source": [
    "# also get the attribute names\n",
    "X, names = dataset.get_data(return_attribute_names=True)\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# also get the data labels and which attributes are categorical\n",
    "# NOTE: look into other flags for get_data() (can't find in API)\n",
    "X, y, categorical = dataset.get_data(\n",
    "    target=dataset.default_target_attribute,\n",
    "    return_categorical_indicator=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing the same stuff with Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'list_tasks_by_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-2d8e72c64be0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# openml doesn't seem to actually support this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_tasks_by_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'list_tasks_by_type'"
     ]
    }
   ],
   "source": [
    "# openml doesn't seem to actually support this\n",
    "tasks = openml.tasks.list_tasks_by_type(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tasks = openml.tasks.list_tasks()\n",
    "tasks_df = pd.DataFrame.from_dict(datasets, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tasks_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# no 'tid' attribute like the website says\n",
    "tasks_df.set_index('tid', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# However, there is a 'did' attribute like in the datasets\n",
    "tasks_df.set_index('did', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems we can do the same stuff with tasks that we did with datasets, but I don't think tasks are sufficiently supported at this point to use them over datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Many Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   23, 27003,   823,   128, 31590, 37642,  4020, 39287, 34865,\n",
       "        3955,  3478,  1160, 23745, 39472, 35886, 39438, 24472, 33527,\n",
       "         774, 38509])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ids = datasets_df[datasets_df.NumberOfInstancesWithMissingValues == 0].index.values\n",
    "dataset_ids_sample = np.random.choice(dataset_ids, 20)\n",
    "dataset_ids_sample[0] = 23\n",
    "dataset_ids_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from openml.exceptions import OpenMLServerError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of datasets: 19327\n",
      "0 of 19327 ... dataset_id: 1 ...\n",
      "Failure\n",
      "1 of 19327 ... dataset_id: 3 ...\n",
      "Success\n",
      "2 of 19327 ... dataset_id: 6 ...\n",
      "Success\n",
      "3 of 19327 ... dataset_id: 8 ...\n",
      "Success\n",
      "4 of 19327 ... dataset_id: 10 ...\n",
      "Success\n",
      "5 of 19327 ... dataset_id: 11 ...\n",
      "Success\n",
      "6 of 19327 ... dataset_id: 12 ...\n",
      "Success\n",
      "7 of 19327 ... dataset_id: 14 ...\n",
      "Success\n",
      "8 of 19327 ... dataset_id: 16 ...\n",
      "Success\n",
      "9 of 19327 ... dataset_id: 18 ...\n",
      "Success\n",
      "10 of 19327 ... dataset_id: 20 ...\n",
      "Success\n",
      "11 of 19327 ... dataset_id: 21 ...\n",
      "Success\n",
      "12 of 19327 ... dataset_id: 22 ...\n",
      "Success\n",
      "13 of 19327 ... dataset_id: 23 ...\n",
      "Success\n",
      "14 of 19327 ... dataset_id: 26 ...\n",
      "Success\n",
      "15 of 19327 ... dataset_id: 28 ...\n",
      "Success\n",
      "16 of 19327 ... dataset_id: 30 ...\n",
      "Success\n",
      "17 of 19327 ... dataset_id: 31 ...\n",
      "Success\n",
      "18 of 19327 ... dataset_id: 32 ...\n",
      "Success\n",
      "19 of 19327 ... dataset_id: 36 ...\n",
      "Success\n",
      "20 of 19327 ... dataset_id: 37 ...\n",
      "Success\n",
      "21 of 19327 ... dataset_id: 39 ...\n",
      "Success\n",
      "22 of 19327 ... dataset_id: 40 ...\n",
      "Success\n",
      "23 of 19327 ... dataset_id: 41 ...\n",
      "Success\n",
      "24 of 19327 ... dataset_id: 43 ...\n",
      "Success\n",
      "25 of 19327 ... dataset_id: 44 ...\n",
      "Success\n",
      "26 of 19327 ... dataset_id: 46 ...\n",
      "Success\n",
      "27 of 19327 ... dataset_id: 48 ...\n",
      "Success\n",
      "28 of 19327 ... dataset_id: 50 ...\n",
      "Success\n",
      "29 of 19327 ... dataset_id: 53 ...\n",
      "Success\n",
      "30 of 19327 ... dataset_id: 54 ...\n",
      "Success\n",
      "31 of 19327 ... dataset_id: 59 ...\n",
      "Success\n",
      "32 of 19327 ... dataset_id: 60 ...\n",
      "Success\n",
      "33 of 19327 ... dataset_id: 61 ...\n",
      "Success\n",
      "34 of 19327 ... dataset_id: 62 ...\n",
      "Success\n",
      "35 of 19327 ... dataset_id: 70 ...\n",
      "Success\n",
      "36 of 19327 ... dataset_id: 71 ...\n",
      "Success\n",
      "37 of 19327 ... dataset_id: 72 ...\n",
      "Success\n",
      "38 of 19327 ... dataset_id: 73 ...\n",
      "Success\n",
      "39 of 19327 ... dataset_id: 74 ...\n",
      "Success\n",
      "40 of 19327 ... dataset_id: 75 ...\n",
      "Success\n",
      "41 of 19327 ... dataset_id: 76 ...\n",
      "Success\n",
      "42 of 19327 ... dataset_id: 77 ...\n",
      "Success\n",
      "43 of 19327 ... dataset_id: 78 ...\n",
      "Success\n",
      "44 of 19327 ... dataset_id: 115 ...\n",
      "Success\n",
      "45 of 19327 ... dataset_id: 116 ...\n",
      "Success\n",
      "46 of 19327 ... dataset_id: 117 ...\n",
      "Success\n",
      "47 of 19327 ... dataset_id: 118 ...\n",
      "Success\n",
      "48 of 19327 ... dataset_id: 119 ...\n",
      "Success\n",
      "49 of 19327 ... dataset_id: 120 ...\n",
      "Success\n",
      "50 of 19327 ... dataset_id: 121 ...\n",
      "Success\n",
      "51 of 19327 ... dataset_id: 122 ...\n",
      "Success\n",
      "52 of 19327 ... dataset_id: 123 ...\n",
      "Success\n",
      "53 of 19327 ... dataset_id: 124 ...\n",
      "Success\n",
      "54 of 19327 ... dataset_id: 125 ...\n",
      "Success\n",
      "55 of 19327 ... dataset_id: 126 ...\n",
      "Success\n",
      "56 of 19327 ... dataset_id: 127 ...\n",
      "Success\n",
      "57 of 19327 ... dataset_id: 128 ...\n",
      "Success\n",
      "58 of 19327 ... dataset_id: 129 ...\n",
      "Success\n",
      "59 of 19327 ... dataset_id: 130 ...\n",
      "Success\n",
      "60 of 19327 ... dataset_id: 131 ...\n",
      "Success\n",
      "61 of 19327 ... dataset_id: 132 ...\n",
      "Success\n",
      "62 of 19327 ... dataset_id: 133 ...\n",
      "Success\n",
      "63 of 19327 ... dataset_id: 134 ...\n",
      "Success\n",
      "64 of 19327 ... dataset_id: 135 ...\n",
      "Success\n",
      "65 of 19327 ... dataset_id: 136 ...\n",
      "Success\n",
      "66 of 19327 ... dataset_id: 137 ...\n",
      "Success\n",
      "67 of 19327 ... dataset_id: 138 ...\n",
      "Success\n",
      "68 of 19327 ... dataset_id: 139 ...\n",
      "Success\n",
      "69 of 19327 ... dataset_id: 140 ...\n",
      "Success\n",
      "70 of 19327 ... dataset_id: 141 ...\n",
      "Success\n",
      "71 of 19327 ... dataset_id: 142 ...\n",
      "Success\n",
      "72 of 19327 ... dataset_id: 143 ...\n",
      "Success\n",
      "73 of 19327 ... dataset_id: 144 ...\n",
      "Success\n",
      "74 of 19327 ... dataset_id: 146 ...\n",
      "Success\n",
      "75 of 19327 ... dataset_id: 147 ...\n",
      "Success\n",
      "76 of 19327 ... dataset_id: 148 ...\n",
      "Success\n",
      "77 of 19327 ... dataset_id: 149 ...\n",
      "Success\n",
      "78 of 19327 ... dataset_id: 150 ...\n",
      "Success\n",
      "79 of 19327 ... dataset_id: 151 ...\n",
      "Success\n",
      "80 of 19327 ... dataset_id: 152 ...\n",
      "Failure\n",
      "81 of 19327 ... dataset_id: 153 ...\n",
      "Failure\n",
      "82 of 19327 ... dataset_id: 154 ...\n",
      "Success\n",
      "83 of 19327 ... dataset_id: 155 ...\n",
      "Success\n",
      "84 of 19327 ... dataset_id: 156 ...\n",
      "Failure\n",
      "85 of 19327 ... dataset_id: 157 ...\n",
      "Failure\n",
      "86 of 19327 ... dataset_id: 158 ...\n",
      "Failure\n",
      "87 of 19327 ... dataset_id: 159 ...\n",
      "Failure\n",
      "88 of 19327 ... dataset_id: 160 ...\n",
      "Failure\n",
      "89 of 19327 ... dataset_id: 161 ...\n",
      "Success\n",
      "90 of 19327 ... dataset_id: 162 ...\n",
      "Success\n",
      "91 of 19327 ... dataset_id: 164 ...\n",
      "Success\n",
      "92 of 19327 ... dataset_id: 180 ...\n",
      "Success\n",
      "93 of 19327 ... dataset_id: 181 ...\n",
      "Success\n",
      "94 of 19327 ... dataset_id: 182 ...\n",
      "Success\n",
      "95 of 19327 ... dataset_id: 183 ...\n",
      "Success\n",
      "96 of 19327 ... dataset_id: 184 ...\n",
      "Success\n",
      "97 of 19327 ... dataset_id: 187 ...\n",
      "Success\n",
      "98 of 19327 ... dataset_id: 189 ...\n",
      "Success\n",
      "99 of 19327 ... dataset_id: 190 ...\n",
      "Success\n",
      "100 of 19327 ... dataset_id: 191 ...\n",
      "Success\n",
      "101 of 19327 ... dataset_id: 192 ...\n",
      "Success\n",
      "102 of 19327 ... dataset_id: 193 ...\n",
      "Success\n",
      "103 of 19327 ... dataset_id: 195 ...\n",
      "Success\n",
      "104 of 19327 ... dataset_id: 197 ...\n",
      "Success\n",
      "105 of 19327 ... dataset_id: 198 ...\n",
      "Success\n",
      "106 of 19327 ... dataset_id: 199 ...\n",
      "Success\n",
      "107 of 19327 ... dataset_id: 201 ...\n",
      "Success\n",
      "108 of 19327 ... dataset_id: 203 ...\n",
      "Success\n",
      "109 of 19327 ... dataset_id: 206 ...\n",
      "Success\n",
      "110 of 19327 ... dataset_id: 207 ...\n",
      "Success\n",
      "111 of 19327 ... dataset_id: 208 ...\n",
      "Success\n",
      "112 of 19327 ... dataset_id: 209 ...\n",
      "Success\n",
      "113 of 19327 ... dataset_id: 210 ...\n",
      "Success\n",
      "114 of 19327 ... dataset_id: 211 ...\n",
      "Success\n",
      "115 of 19327 ... dataset_id: 212 ...\n",
      "Success\n",
      "116 of 19327 ... dataset_id: 214 ...\n",
      "Success\n",
      "117 of 19327 ... dataset_id: 215 ...\n",
      "Success\n",
      "118 of 19327 ... dataset_id: 216 ...\n",
      "Success\n",
      "119 of 19327 ... dataset_id: 217 ...\n",
      "Success\n",
      "120 of 19327 ... dataset_id: 218 ...\n",
      "Success\n",
      "121 of 19327 ... dataset_id: 223 ...\n",
      "Success\n",
      "122 of 19327 ... dataset_id: 225 ...\n",
      "Success\n",
      "123 of 19327 ... dataset_id: 226 ...\n",
      "Success\n",
      "124 of 19327 ... dataset_id: 227 ...\n",
      "Success\n",
      "125 of 19327 ... dataset_id: 228 ...\n",
      "Success\n",
      "126 of 19327 ... dataset_id: 229 ...\n",
      "Success\n",
      "127 of 19327 ... dataset_id: 230 ...\n",
      "Success\n",
      "128 of 19327 ... dataset_id: 244 ...\n",
      "Success\n",
      "129 of 19327 ... dataset_id: 245 ...\n",
      "Success\n",
      "130 of 19327 ... dataset_id: 246 ...\n",
      "Success\n",
      "131 of 19327 ... dataset_id: 247 ...\n",
      "Success\n",
      "132 of 19327 ... dataset_id: 248 ...\n",
      "Success\n",
      "133 of 19327 ... dataset_id: 249 ...\n",
      "Success\n",
      "134 of 19327 ... dataset_id: 250 ...\n"
     ]
    },
    {
     "ename": "ChunkedEncodingError",
     "evalue": "('Connection broken: IncompleteRead(0 bytes read, 2 more expected)', IncompleteRead(0 bytes read, 2 more expected))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    185\u001b[0m                     \u001b[0mcache_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0;31m# (which is implemented in terms of self.readinto)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTTPResponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readinto_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/http/client.py\u001b[0m in \u001b[0;36m_readinto_chunked\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;31m# we read the whole chunk, get another\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# toss the CRLF at the end of the chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m             \u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/http/client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m             \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIncompleteRead\u001b[0m: IncompleteRead(0 bytes read, 2 more expected)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    652\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;31m# This includes IncompleteRead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mProtocolError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Connection broken: %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProtocolError\u001b[0m: ('Connection broken: IncompleteRead(0 bytes read, 2 more expected)', IncompleteRead(0 bytes read, 2 more expected))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mChunkedEncodingError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-e14f707da7de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'of'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_datasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'...'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dataset_id:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mgood_dataset_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Success'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nealbray/.local/lib/python3.4/site-packages/openml-0.3.0-py3.4.egg/openml/datasets/functions.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(dataset_id)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0m_remove_dataset_cache_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdid_cache_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_dataset_from_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marff_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nealbray/.local/lib/python3.4/site-packages/openml-0.3.0-py3.4.egg/openml/datasets/functions.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(dataset_id)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_dataset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdid_cache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0marff_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_dataset_arff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdid_cache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_dataset_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdid_cache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;31m# TODO not used yet, figure out what to do with this...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nealbray/.local/lib/python3.4/site-packages/openml-0.3.0-py3.4.egg/openml/datasets/functions.py\u001b[0m in \u001b[0;36m_get_dataset_arff\u001b[0;34m(did_cache_dir, description)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'oml:url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m     \u001b[0marff_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nealbray/.local/lib/python3.4/site-packages/openml-0.3.0-py3.4.egg/openml/_api_calls.py\u001b[0m in \u001b[0;36m_read_url\u001b[0;34m(url, data)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;31m# Using requests.post sets header 'Accept-encoding' automatically to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# 'gzip,deflate'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \"\"\"\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    455\u001b[0m         }\n\u001b[1;32m    456\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mcontent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    722\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    654\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mContentDecodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mChunkedEncodingError\u001b[0m: ('Connection broken: IncompleteRead(0 bytes read, 2 more expected)', IncompleteRead(0 bytes read, 2 more expected))"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# dataset_ids = dataset_ids_sample\n",
    "num_datasets = len(dataset_ids)\n",
    "good_dataset_ids = []\n",
    "num_failed_datasets = 0\n",
    "\n",
    "print('Total number of datasets:', num_datasets)\n",
    "for i, dataset_id in enumerate(dataset_ids):\n",
    "    print(i, 'of', num_datasets, '...', 'dataset_id:', dataset_id, '...')\n",
    "    try:\n",
    "        dataset = openml.datasets.get_dataset(dataset_id)\n",
    "        good_dataset_ids.append(dataset_id)\n",
    "        print('Success')\n",
    "    except OpenMLServerError:\n",
    "        num_failed_datasets += 1\n",
    "        print('Failure')\n",
    "#     if i + 1 % 100 == 0:\n",
    "#         with open('good_dataset_ids.pickle', 'rb') as handle:\n",
    "#             past_good_ids = pickle.load(handle)['ids']\n",
    "            \n",
    "#         print(len(past_good_ids), 'encountered in the past')\n",
    "#         print('Additional', len(good_dataset_ids), 'elements being added to file...'\n",
    "              \n",
    "#         with open('good_dataset_ids.pickle', 'wb') as handle:\n",
    "#             pickle.dump(good_dataset_ids, handle)\n",
    "    \n",
    "        \n",
    "# with open('good_dataset_ids.pickle', 'wb') as handle:\n",
    "#     pickle.dump(good_dataset_ids, handle)        \n",
    "\n",
    "print('Number of failed datasets:', num_failed_datasets)\n",
    "print('Number of good datasets:', len(good_dataset_ids))\n",
    "print('Check partition:', num_failed_datasets + len(good_dataset_ids), '=?', num_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Number of failed datasets:', num_failed_datasets)\n",
    "print('Number of good datasets:', len(good_dataset_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('good_dataset_ids.pickle', 'wb') as handle:\n",
    "    pickle.dump({'i': i, 'ids': good_dataset_ids}, handle)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('good_dataset_ids.pickle', 'rb') as handle:\n",
    "    test = pickle.load(handle)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_metadata = openml.datasets.list_datasets()\n",
    "metadata_df = pd.DataFrame.from_dict(dataset_metadata, orient='index')\n",
    "filtered_df = metadata_df[metadata_df.NumberOfInstancesWithMissingValues == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y, categorical, names = dataset.get_data(\n",
    "            target=dataset.default_target_attribute,\n",
    "            return_categorical_indicator=True,\n",
    "            return_attribute_names=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
